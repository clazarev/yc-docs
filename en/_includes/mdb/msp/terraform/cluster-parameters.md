Here is an example of the configuration file structure:

```hcl
resource "yandex_spark_cluster" "<cluster_name>" {
  description         = "<cluster_description>"
  name                = "<cluster_name>"
  folder_id           = "<folder_ID>"
  service_account_id  = "<service_account_ID>"
  deletion_protection = <protect_cluster_from_deletion>

  labels = {
    <label_list>
  }

  network = {
    subnet_ids         = ["<list_of_subnet_IDs>"]
    security_group_ids = ["<list_of_security_group_IDs>"]
  }

  config = {
    resource_pools = {
      driver = {
        resource_preset_id = "<host_class>"
        size               = <fixed_number_of_instances>
      }
      executor = {
        resource_preset_id = "<host_class>"
        size               = <fixed_number_of_instances>
      }
    }
  }

  logging = {
    enabled      = <enable_logging>
    folder_id    = "<folder_ID>"
  }

}

resource "yandex_vpc_network" "<network_name>" {
  name = "<network_name>"
}

resource "yandex_vpc_subnet" "<subnet_name>" {
  name           = "<subnet_name>"
  zone           = "<availability_zone>"
  network_id     = "<network_ID>"
  v4_cidr_blocks = ["<range>"]
}
```

Where:

* `description`: Cluster description. This is an optional parameter.
* `name`: Cluster name.
* `folder_id`: Folder ID. This is an optional parameter. If the value is missing, the cluster will reside in the folder specified in the provider settings.
* `service_account_id`: Service account ID.
* `deletion_protection`: Cluster protection from accidental deletion, `true` or `false`. This is an optional parameter.
* `labels`: List of labels. This is an optional parameter. Provide labels in `<key> = "<value>"` format.
* `subnet_ids`: Subnet IDs list.
* `security_group_ids`: List of security group IDs.
* `driver`: Host configuration to run {{ SPRK }} drivers. In this section, specify:

  * [Host class](../../../../managed-spark/concepts/instance-types.md) in the `resource_preset_id` parameter.
  * Number of instances. Specify a fixed number in the `size` parameter or the minimum and maximum number for autoscaling in the `min_size` and `max_size` parameters.

* `executor`: Host configuration to run {{ SPRK }} executors. In this section, specify:

  * [Host class](../../../../managed-spark/concepts/instance-types.md) in the `resource_preset_id` parameter.
  * Number of instances. Specify a fixed number in the `size` parameter or the minimum and maximum number for autoscaling in the `min_size` and `max_size` parameters.
      
* `logging`: Logging parameters. Logs generated by {{ SPRK }} components will be sent to {{ cloud-logging-full-name }}. To enable logging:

    * Set the `enabled = true` value.
    * Specify one of two log storage locations:
    
      * `folder_id`: Folder ID. Logs will be written to the default [log group](../../../../logging/concepts/log-group.md) for this folder.
      * `log_group_id`: Custom log group ID. Logs will be written to this group.
