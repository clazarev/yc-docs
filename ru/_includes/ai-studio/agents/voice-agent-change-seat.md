```python
import asyncio
import json
import base64
import websockets
import wave
import subprocess


API_KEY = "<API-–∫–ª—é—á>"
FOLDER = "<–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä_–∫–∞—Ç–∞–ª–æ–≥–∞>"
INPUT_FILE = "<–ø—É—Ç—å_–∫_–≤—Ö–æ–¥–Ω–æ–º—É_–∞—É–¥–∏–æ—Ñ–∞–π–ª—É>"
CONVERTED_FILE = "./converted.wav"
OUTPUT_FILE = "./output.wav"
CHUNK_SIZE = 15000  # —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ –±–∞–π—Ç–∞—Ö (~100–º—Å –ø—Ä–∏ 24kHz mono PCM16)

REALTIME_URL = f"wss://rest-assistant.api.cloud.yandex.net/v1/realtime/openai?model=gpt://{FOLDER}/speech-realtime-250923"

def make_silence_chunk(samples: int):
    """–°–æ–∑–¥–∞–µ—Ç —á–∞–Ω–∫ —Ç–∏—à–∏–Ω—ã –∑–∞–¥–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã (samples) –≤ —Ñ–æ—Ä–º–∞—Ç–µ PCM16."""
    return b"\x00\x00" * samples


async def main():
    # 1Ô∏è‚É£ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç Realtime API:
    # mono, 24kHz, 16-bit PCM. –ë–µ–∑ —ç—Ç–æ–≥–æ –º–æ–¥–µ–ª—å –Ω–µ –ø—Ä–∏–º–µ—Ç –∞—É–¥–∏–æ.
    print("üéß –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞...")
    subprocess.run([
        "ffmpeg", "-y", "-i", INPUT_FILE,
        "-ac", "1", "-ar", "24000", "-sample_fmt", "s16",
        CONVERTED_FILE
    ], check=True)
    print(f"‚úÖ Converted {INPUT_FILE} -> {CONVERTED_FILE}")

    # 2Ô∏è‚É£ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º WebSocket-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Realtime API.
    async with websockets.connect(
            REALTIME_URL,
            additional_headers=[("Authorization", f"api-key {API_KEY}")]
    ) as ws:
        print("‚úÖ Connected to Realtime API")

        # 3Ô∏è‚É£ –ñ–¥—ë–º –ø–µ—Ä–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ "session.created" —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Å–µ—Å—Å–∏–∏.
        created = json.loads(await ws.recv())
        print("‚úÖ Session created:", created)

        # 4Ô∏è‚É£ –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é: –≤–∫–ª—é—á–∞–µ–º server_vad, –≤—ã–±–∏—Ä–∞–µ–º –≥–æ–ª–æ—Å –∏ —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞.
        await ws.send(json.dumps({
            "type": "session.update",
            "session": {
                "type": "realtime",
                "output_modalities": ["text", "audio"],  # —Ö–æ—Ç–∏–º –∏ —Ç–µ–∫—Å—Ç, –∏ –∑–≤—É–∫
                "audio": {
                    "input": {
                        # –§–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ
                        "format": {"type": "audio/pcm", "rate": 24000},
                        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è server-side VAD
                        "turn_detection": {
                            "type": "server_vad",  # –≤–∫–ª—é—á–∞–µ–º —Å–µ—Ä–≤–µ—Ä–Ω—ã–π VAD
                            "threshold": 0.5,  # —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                            "silence_duration_ms": 400,  # —Ç–∏—à–∏–Ω–∞, —Å—á–∏—Ç–∞—é—â–∞—è—Å—è –∫–æ–Ω—Ü–æ–º —Ä–µ—á–∏
                        }
                    },
                    "output": {
                        "format": {"type": "audio/pcm", "rate": 44100},
                        "voice": "marina"
                    }
                },
                "instructions": """
            –ï—Å–ª–∏ –±—É–¥—É—Ç —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å –ø—Ä–æ —Å–º–µ–Ω—É –º–µ—Å—Ç –≤ —Å–∞–º–æ–ª–µ—Ç–µ, –¥–µ–ª–∞–π –≤–∏–¥, —á—Ç–æ –≤—Å–µ –ø–æ–Ω—è–ª–∞ –∏ —Å–¥–µ–ª–∞–ª–∞. 
–í –æ—Ç–≤–µ—Ç–µ —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π –ø—Ä–∞–≤–∏–ª–∞–º:
–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ. 
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∑—ã–≤–∞–ª –Ω–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞, –º–µ—Å—Ç–∞, –∞–¥—Ä–µ—Å –∏–ª–∏ –¥—Ä—É–≥—É—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –æ—Ç–≤–µ—Ç–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≥–æ–≤–æ—Ä–∏ —ç—Ç–æ - —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–Ω—è–ª, —á—Ç–æ –µ–≥–æ –≤–≤–æ–¥–Ω—ã–µ –±—ã–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É—Å–ª—ã—à–∞–Ω—ã.
–û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ, –í —Ü–µ–ª–æ–º, —Ñ–æ—Ä–º–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã —Ç–∞–∫, —á—Ç–æ–±—ã –∏—Ö –±—ã–ª–æ —É–¥–æ–±–Ω–æ —Å–ª—É—à–∞—Ç—å.
            """
            }
        }))

        # 5Ô∏è‚É£ –ß–∏—Ç–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π WAV –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ –∫—É—Å–æ—á–∫–∞–º.
        with wave.open(CONVERTED_FILE, "rb") as wf:
            assert wf.getframerate() == 24000, "–û–∂–∏–¥–∞–ª—Å—è 24kHz"
            audio_bytes = wf.readframes(wf.getnframes())
            samples_per_chunk = CHUNK_SIZE // 2  # —Ç.–∫. 2 –±–∞–π—Ç–∞ = 1 sample
            print(f"üìä –û—Ç–ø—Ä–∞–≤–ª—è–µ–º {len(audio_bytes)} –±–∞–π—Ç ({wf.getnframes()} —Ñ—Ä–µ–π–º–æ–≤)")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞–º–∏
        for i in range(0, len(audio_bytes), CHUNK_SIZE):
            await ws.send(json.dumps({
                "type": "input_audio_buffer.append",
                "audio": base64.b64encode(audio_bytes[i:i + CHUNK_SIZE]).decode("ascii")
            }))

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º ~500–º—Å —Ç–∏—à–∏–Ω—ã –≤ –∫–æ–Ω—Ü–µ, —á—Ç–æ–±—ã VAD –Ω–∞–¥—ë–∂–Ω–æ "—É–≤–∏–¥–µ–ª" –∫–æ–Ω–µ—Ü —Ä–µ—á–∏
        silence_chunk = make_silence_chunk(samples_per_chunk)
        for _ in range(5):  # 5 * 100–º—Å = 500–º—Å
            await ws.send(json.dumps({
                "type": "input_audio_buffer.append",
                "audio": base64.b64encode(silence_chunk).decode("ascii")
            }))

        committed = False  # –±—É–¥–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å, —á—Ç–æ –±—É—Ñ–µ—Ä –∫–æ–º–º–∏—Ç–Ω—É—Ç
        full_text, audio_chunks = [], []

        try:
            while True:
                msg = await ws.recv()
                data = json.loads(msg)
                print("üì• Event:", data)

                if data.get("type") == "input_audio_buffer.committed" and not committed:
                    committed = True
                    print("‚úÖ Audio buffer committed ‚Äî —Å–æ–∑–¥–∞—ë–º response...")
                    await ws.send(json.dumps({
                        "type": "response.create",
                        "response": {
                            "instructions": "–ö—Ä–∞—Ç–∫–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–∑ –∞—É–¥–∏–æ."
                        }
                    }))

                # –°–æ–±–∏—Ä–∞–µ–º –∞—É–¥–∏–æ –¥–µ–ª—å—Ç—ã, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–∏—Å—ã–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç
                if data.get("type") == "response.output_audio.delta":
                    audio_chunks.append(base64.b64decode(data["delta"]))

                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–µ–ª—å—Ç—ã, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–∏—Å—ã–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç
                if data.get("type") == "response.output_text.delta":
                    full_text.append(data["delta"])

                # –ö–æ–≥–¥–∞ –æ—Ç–≤–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤ ‚Üí –ø–µ—á–∞—Ç–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ
                if data.get("type") == "response.done":
                    print("‚úÖ Response completed")
                    if full_text:
                        print("üìù –ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç:", "".join(full_text))
                    if audio_chunks:
                        with wave.open(OUTPUT_FILE, "wb") as wf:
                            wf.setnchannels(1)
                            wf.setsampwidth(2)
                            wf.setframerate(44100)
                            wf.writeframes(b"".join(audio_chunks))
                        print(f"üîä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∞—É–¥–∏–æ –≤ {OUTPUT_FILE}")
                    break

        except websockets.ConnectionClosed:
            print("üîå Connection closed by server")


if __name__ == "__main__":
    asyncio.run(main())
```