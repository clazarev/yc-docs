---
title: Взаимосвязь ресурсов в {{ msp-full-name }}
description: '{{ msp-full-name }} — это управляемый сервис для развертывания кластеров {{ SPRK }} и запуска Spark/PySpark-заданий в инфраструктуре {{ yandex-cloud }}.'
---

# Взаимосвязь ресурсов в {{ msp-full-name }}

{{ msp-full-name }} — это управляемый сервис для развертывания кластеров {{ SPRK }} и запуска Spark/PySpark-заданий в инфраструктуре {{ yandex-cloud }}.

{{ msp-full-name }} позволяет:
* Разворачивать кластеры {{ SPRK }} и управлять ими через консоль управления, Terraform и API без необходимости вручную администрировать кластеры и виртуальные машины. 
* Конфигурировать пул хостов для драйверов и пул хостов для исполнителей независимо друг от друга.
* Запускать задания на Python, Scala и Java, гибко управляя их настройками.
* Декларативно определять зависимости заданий, включая Pip-, Deb- и Maven-пакеты.
* Следить за ходом выполнения заданий в веб-интерфейсе Spark-приложений и анализировать результаты с помощью логов в {{ cloud-logging-full-name }} и [Spark History Server](https://spark.apache.org/docs/latest/monitoring.html).
* Выгружать результаты выполнения заданий в {{ objstorage-name }}, базы данных и аналитические витрины.
* Подключать {{ metastore-full-name }} в конфигурации кластера или в параметрах задания.
* Задавать предпочтительный день недели и время для технического обслуживания кластера.

## Понятия и сущности {#concepts}

Основная сущность, которой оперирует сервис {{ msp-full-name }}, — _[кластер](../../glossary/cluster.md) {{ SPRK }}_.

При запуске в кластере [задания](#job) создается приложение Spark. Приложение включает в себя следующие процессы:
* Драйвер — управляющий процесс, который строит план задания, разбивает работу на стадии и задачи, следит за очередью задач, а также запрашивает создание исполнителей и освобождает их.
* Исполнители — процессы, отвечающие за выполнение отдельных задач в рамках задания.

### Пулы хостов {#pools}

Кластер {{ SPRK }} состоит из трех групп хостов (пулов):

* Пул хостов для драйверов — служит для запуска драйверов и ряда служебных компонентов (работа с сетью, логами, метриками и т. д.).

* Пул хостов для исполнителей — служит для запуска исполнителей и некоторых служебных компонентов.

* Вспомогательный пул — служит для запуска Spark History Server и других системных компонентов.

Пул хостов для драйверов и пул хостов для исполнителей можно конфигурировать, задавая количество хостов в каждом пуле и [их класс](instance-types.md). Количество хостов в каждом из двух пулов может быть фиксированным или изменяться динамически. Конфигурирование пулов выполняется при [создании](../operations/cluster-create.md) или [изменении](../operations/cluster-update.md) кластера {{ SPRK }}. 

## Задание {#job}

Задание — это спецификация запуска приложения Spark на выбранном кластере {{ SPRK }}.

В задание входят:
* Целевой кластер {{ SPRK }}.

  {% note info %}

  Часть [конфигурации кластера](#cluster-configuration) задает параметры задания по умолчанию и может быть переопределена на уровне задания. Не могут быть переопределены: сетевые настройки, сервисный аккаунт, Deb-пакеты, использование Spark History Server и настройки логирования.

  {% endnote %}

* Тип задания — `Spark` для Java и Scala или `PySpark` для Python.
* Исполняемый модуль и точка входа — JAR-файл и основной класс для задания типа `Spark` или PY-файл для задания типа `PySpark`.
* Аргументы запуска.
* Свойства Spark — ресурсы запуска, параметры динамической аллокации и параллелизма, SQL-параметры и т. д.
* Библиотеки и файлы — JAR-файлы, Maven-пакеты, дополнительные файлы и архивы.

## Параллелизм и автомасштабирование {#parallel}

На одном хосте для драйверов может одновременно выполняться одно или несколько заданий. Точное число зависит от:
* класса [хостов для драйверов](instance-types.md), то есть объема памяти и количества ядер у одного хоста;
* объема ресурсов, которые запрашивает каждое [задание](#job);
* объема зарезервированных под внутренние нужды ресурсов хоста.

При этом число хостов для драйверов может:
* быть фиксированным, если автомасштабирование хостов для драйверов выключено;
* изменяться динамически в зависимости от количества свободных ядер и объема свободной памяти, если автомасштабирование хостов для драйверов включено.

Таким образом, количество заданий, которые могут одновременно выполняться на кластере {{ SPRK }}, зависит от следующих факторов:
* заданного числа хостов для драйверов или настроек автомасштабирования;
* класса хостов;
* параметров каждого задания;
* объема зарезервированных под внутренние нужды ресурсов.
